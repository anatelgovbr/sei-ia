x-common: 
  environment: &otel-common-env                                                                                                                                                         
     OTEL_EXPORTER_OTLP_ENDPOINT: ${OTEL_EXPORTER_OTLP_ENDPOINT}                                                                                                              
     OTEL_EXPORTER_OTLP_PROTOCOL: ${OTEL_EXPORTER_OTLP_PROTOCOL}                                                                                                              
     OTEL_SERVICE_NAME: ${OTEL_SERVICE_NAME}                                                                                                                                  
     OTEL_EXPORTER_OTLP_INSECURE: ${OTEL_EXPORTER_OTLP_INSECURE}                                                                                                              
     OTEL_METRICS_EXPORTER: ${OTEL_METRICS_EXPORTER}                                                                                                                          
     OTEL_EXPORTER_OTLP_METRICS_PROTOCOL: ${OTEL_EXPORTER_OTLP_METRICS_PROTOCOL}                                                                                              
     OTEL_TRACES_EXPORTER: ${OTEL_TRACES_EXPORTER}                                                                                                                            
     OTEL_EXPORTER_OTLP_TRACES_PROTOCOL: ${OTEL_EXPORTER_OTLP_TRACES_PROTOCOL}

x-airflow-common: &airflow-common
  # In order to add custom dependencies or upgrade provider packages you can use your extended image.
  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml
  # and uncomment the "build" line below, Then run `docker-compose build` to build the images.
  #image: apache/airflow:2.6.3
  # build: .
  image: ${DOCKER_REGISTRY:-}airflow-webserver-pd:${AIRFLOW_IMAGE_NAME}
  build:
    context: .
    dockerfile: ./airflow.dockerfile
    network: host
    args:
      AIRFLOW_UID: ${AIRFLOW_UID:-50000}
      NB_USER: ${NB_USER}
      NB_UID: ${NB_UID}
      NB_GID: ${NB_GID}
      GIT_TOKEN: ${GIT_TOKEN}
      DB_SEI_HOST : ${DB_SEI_HOST}
      DB_SEI_PORT : ${DB_SEI_PORT}
      DB_SEI_USER : ${DB_SEI_USER}
      DB_SEI_PWD : ${DB_SEI_PWD}
      DB_SEI_DATABASE : ${DB_SEI_DATABASE}
      ASSISTENTE_PGVECTOR_HOST : ${ASSISTENTE_PGVECTOR_HOST}
      ASSISTENTE_PGVECTOR_USER : ${ASSISTENTE_PGVECTOR_USER}
      ASSISTENTE_PGVECTOR_PWD : ${ASSISTENTE_PGVECTOR_PWD}
      ASSISTENTE_PGVECTOR_DB : ${ASSISTENTE_PGVECTOR_DB}
      SEI_SOLR_ADDRESS : ${SEI_SOLR_ADDRESS}
      SEI_SOLR_CORE : ${SEI_SOLR_CORE}
      EMBEDDINGS_TABLE_NAME : ${EMBEDDINGS_TABLE_NAME}
      DATABASE_TYPE : ${DATABASE_TYPE}
      EMBEDDER_PROJ_URL : ${EMBEDDER_PROJ_URL}
      PRE_TRAINED_SBERT_PATH: ${PRE_TRAINED_SBERT_PATH}
      EMBEDDING_STRATEGY: ${EMBEDDING_STRATEGY}
      ALLOWED_EMBEDDING_FIELDS: ${ALLOWED_EMBEDDING_FIELDS}
      ALLOWED_EMBEDDING_TYPES: ${ALLOWED_EMBEDDING_TYPES}
  networks:
    - network1
  env_file:
    - ./airflow.env
  environment: &airflow-common-env
    GIT_TOKEN: ${GIT_TOKEN}
    POSTGRES_DB_ASSISTENTE_SCHEMA : ${POSTGRES_DB_ASSISTENTE_SCHEMA}
    ASSISTENTE_PGVECTOR_HOST : ${ASSISTENTE_PGVECTOR_HOST}
    ASSISTENTE_PGVECTOR_USER : ${ASSISTENTE_PGVECTOR_USER}
    ASSISTENTE_PGVECTOR_PWD : ${ASSISTENTE_PGVECTOR_PWD}
    ASSISTENTE_PGVECTOR_DB : ${ASSISTENTE_PGVECTOR_DB}
    LOG_LEVEL: ${LOG_LEVEL}

    TZ: America/Sao_Paulo
    AIRFLOW__LOGGING__LOGGING_LEVEL: ${LOG_LEVEL}
    AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: ${AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG}
    AIRFLOW_API_BASE_URL: "http://airflow-webserver-pd:8080/api/v1"
    #configuração do ETL da nossa aplicação
    SOLR_MLT_PROCESS_CORE: ${SOLR_MLT_PROCESS_CORE}
    SOLR_MLT_JURISPRUDENCE_CORE: ${SOLR_MLT_JURISPRUDENCE_CORE}
    MLT_PROCESS_CONFIGSET: "/var/solr/configsets/process"
    MLT_JURISPRUDENCE_CONFIGSET: "/var/solr/configsets/jurisprudence"

    ENVIRONMENT: ${ENVIRONMENT}

    AIRFLOW_HOME: /opt/airflow
    # WARNING: Use _PIP_ADDITIONAL_REQUIREMENTS option ONLY for a quick checks
    # for other purpose (development, test and especially production usage) build/extend Airflow image.
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    LD_PRELOAD: /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #bug airflow /usr/lib/x86_64-linux-gnu/libstdc++.so.6: cannot allocate memory in static TLS block
    PIP_CACHE_DIR: ${STORAGE_PROJ_DIR}/pip_cache

    # Stack sei-similaridade
    AIRFLOW_DB_EXTERNAL_CONNECTION: true
    API_VERSION: ${API_SEI_IMAGE}
    APP_VERSION: ${APP_API}
    SOLR_ADDRESS: ${SOLR_ADDRESS}
    CONN_STRING_APP_DB: "postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@pgvector_all/sei_similaridade"
    CONN_LOG_DB_STRING: "postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@pgvector_all/sei_similaridade"

    DB_SEI_USER: ${DB_SEI_USER}
    DB_SEI_PWD: ${DB_SEI_PWD}
    DB_SEI_HOST: ${DB_SEI_HOST}
    DB_SEI_PORT: ${DB_SEI_PORT}
    DB_SEI_DATABASE: ${DB_SEI_DATABASE}
    DB_SEI_SCHEMA: ${DB_SEI_SCHEMA}
    DATABASE_TYPE: ${DATABASE_TYPE}

    AIRFLOW_CONN_DB_SEI_ORACLE: "oracle://${DB_SEI_USER}:${DB_SEI_PWD}@${DB_SEI_HOST}:${DB_SEI_PORT}/?sid=xe&mode=SYSDBA"
    AIRFLOW_CONN_DB_SEI_MSSQL: "mssql+pymssql://${DB_SEI_USER}:${DB_SEI_PWD}@${DB_SEI_HOST}:${DB_SEI_PORT}/${DB_SEI_DATABASE}"
    AIRFLOW_CONN_DB_SEI_MYSQL: "mysql://${DB_SEI_USER}:${DB_SEI_PWD}@${DB_SEI_HOST}:${DB_SEI_PORT}/${DB_SEI_DATABASE}"

    CONN_SEI_STRING: "mysql+pymysql://${DB_SEI_USER}:${DB_SEI_PWD}@${DB_SEI_HOST}"
    CONN_SEI_DATABASE: ${DB_SEI_DATABASE}
    SEI_SOLR_ADDRESS: ${SEI_SOLR_ADDRESS}
    SEI_SOLR_CORE: ${SEI_SOLR_CORE}
    SEI_IAWS_URL : ${SEI_IAWS_URL}
    SEI_IAWS_KEY : ${SEI_IAWS_KEY}
    STORAGE_PROJ_DIR: ${STORAGE_PROJ_DIR}
    CONFIG_MLT_FIELDS_WEIGHTS_PATH: ${STORAGE_PROJ_DIR}/configs/conf_mlt_fields_weights.json
    APP_API_RECOMMENDER_URL: "http://api_sei:8082/process-recommenders/weighted-mlt-recommender/recommendations-by-id-protocolo/{}?rows=5&debug=false"

    HF_HOME: "${STORAGE_PROJ_DIR}/cache/transformers"
    EMBEDDING_MODEL: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    MAX_LENGTH_CHUNK_SIZE: "128"
    EMBEDDINGS_TABLE_NAME: "embeddings_400_50"
    EMBEDDER_PROJ_URL: ${EMBEDDER_PROJ_URL}
    PRE_TRAINED_SBERT_PATH: ${PRE_TRAINED_SBERT_PATH}
    EMBEDDING_STRATEGY: ${EMBEDDING_STRATEGY}
    ALLOWED_EMBEDDING_FIELDS: ${ALLOWED_EMBEDDING_FIELDS}
    ALLOWED_EMBEDDING_TYPES: ${ALLOWED_EMBEDDING_TYPES}

  volumes: &airflow-common-volumes
    - airflow-jobs:/home/airflow/app/jobs
    - airflow-logs-volume:/opt/airflow/logs
    - ${STORAGE_PROJ_DIR}:${STORAGE_PROJ_DIR}

  user: "${AIRFLOW_UID:-50000}:0"
  depends_on: &airflow-common-depends-on
    rabbitmq-pd:
      condition: service_healthy
    airflow_postgres-pd:
      condition: service_healthy

services:
  airflow_postgres-pd:
    profiles:
      - all
      - airflow
      - externo
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
      PGPORT: 5433
      TZ: America/Sao_Paulo
    #command: postgres -c config_file=/etc/postgresql/postgresql.conf
    volumes:
      - airflow-postgres-db-volume:/var/lib/postgresql/data

    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always
    networks:
      - network1
    deploy:
      resources:
        limits:
          memory: ${AIRFLOW_POSTGRES_MEM_LIMIT}
          cpus: ${AIRFLOW_POSTGRES_CPU_LIMIT}

  rabbitmq-pd:
    image: rabbitmq:3-management
    hostname: rabbitmq
    profiles:
      - all
      - airflow
      - externo
    environment:
      RABBITMQ_ERLANG_COOKIE: SWQOKODSQALRPCLNMEQG
      RABBITMQ_DEFAULT_USER: airflow
      RABBITMQ_DEFAULT_PASS: airflow
      TZ: America/Sao_Paulo
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes: *airflow-common-volumes

    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 10s
      timeout: 30s
      retries: 5
    restart: always
    networks:
      - network1
    deploy:
      resources:
        limits:
          memory: ${RABBITMQ_MEM_LIMIT}
          cpus: ${RABBITMQ_CPU_LIMIT}

  airflow-webserver-pd:
    <<: *airflow-common
    command: webserver
    profiles:
      - all
      - airflow
      - externo
    ports:
      - "8081:8080"
    healthcheck:
      test: ["CMD", "sh", "/home/airflow/app/healthcheck/airflow_webserver.sh"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init-pd:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          memory: ${AIRFLOW_WEBSERVER_MEM_LIMIT}
          cpus: ${AIRFLOW_WEBSERVER_CPU_LIMIT}
    volumes: *airflow-common-volumes

  airflow-scheduler-pd:
    <<: *airflow-common
    cpu_shares: ${AIRFLOW_SCHEDULER_CPU_SHARES}
    command: scheduler
    profiles:
      - all
      - airflow
      - externo
    healthcheck:
      test: ["CMD", "sh", "/home/airflow/app/healthcheck/airflow_scheduler.sh"]
      interval: 30s
      timeout: 60s
      retries: 10
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init-pd:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          memory: ${AIRFLOW_SCHEDULER_MEM_LIMIT}
          cpus: ${AIRFLOW_SCHEDULER_CPU_LIMIT}
      replicas: 1
    volumes: *airflow-common-volumes

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    profiles:
      - all
      - airflow
      - externo
    healthcheck:
      test: ["CMD", "sh", "/home/airflow/app/healthcheck/airflow_worker.sh"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    environment:
      <<: *airflow-common-env
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: "0"
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init-pd:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          memory: ${AIRFLOW_WORKER_MEM_LIMIT}
          cpus: ${AIRFLOW_WORKER_CPU_LIMIT}
      replicas: ${AIRFLOW_WORKERS_REPLICAS}
    volumes: *airflow-common-volumes

  airflow-triggerer-pd:
    <<: *airflow-common
    profiles:
      - all
      - airflow
      - externo
    command: triggerer
    healthcheck:
      test: ["CMD", "sh", "/home/airflow/app/healthcheck/airflow_triggerer.sh"]
      interval: 30s
      timeout: 60s
      retries: 10
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init-pd:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          memory: ${AIRFLOW_TRIGGERER_MEM_LIMIT}
          cpus: ${AIRFLOW_TRIGGERER_CPU_LIMIT}
    volumes: *airflow-common-volumes

  airflow-init-pd:
    <<: *airflow-common
    entrypoint: /bin/bash
    profiles:
      - all
      - airflow
      - externo
    # yamllint disable rule:line-length
    command:
      - -c
      - |
        if [[ -z "${AIRFLOW_UID}" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m"
          echo "If you are on Linux, you SHOULD follow the instructions below to set "
          echo "AIRFLOW_UID environment variable, otherwise files will be owned by root."
          echo "For other operating systems you can get rid of the warning with manually created .env file:"
          echo "    See: https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#setting-the-right-airflow-user"
          echo
        fi
        one_meg=1048576
        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
        disk_available=$$(df / | tail -1 | awk '{print $$4}')
        warning_resources="false"
        if (( mem_available < 4000 )) ; then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough memory available for Docker.\e[0m"
          echo "At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))"
          echo
          warning_resources="true"
        fi
        if (( cpus_available < 2 )); then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\e[0m"
          echo "At least 2 CPUs recommended. You have $${cpus_available}"
          echo
          warning_resources="true"
        fi
        if (( disk_available < one_meg * 10 )); then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\e[0m"
          echo "At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))"
          echo
          warning_resources="true"
        fi
        if [[ $${warning_resources} == "true" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\e[0m"
          echo "Please follow the instructions to increase amount of resources available:"
          echo "   https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#before-you-begin"
          echo
        fi
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R "${AIRFLOW_UID}:0" /sources/{logs,dags,plugins}
        exec /entrypoint airflow version
    # yamllint enable rule:line-length
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: "true"
      _AIRFLOW_WWW_USER_CREATE: "true"
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
      _PIP_ADDITIONAL_REQUIREMENTS: ""
    user: "0:0"

  airflow-cli:
    <<: *airflow-common
    profiles:
      - debug
    environment:
      <<: *airflow-common-env
      CONNECTION_CHECK_MAX_COUNT: "0"
    # Workaround for entrypoint issue. See: https://github.com/apache/airflow/issues/16252
    command:
      - bash
      - -c
      - airflow

  # You can enable flower by adding "--profile flower" option e.g. docker-compose --profile flower up
  # or by explicitly targeted on the command line e.g. docker-compose up flower.
  # See: https://docs.docker.com/compose/profiles/
  flower:
    <<: *airflow-common
    command: celery flower
    profiles:
      - flower
    ports:
      - "5555:5555"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init-pd:
        condition: service_completed_successfully
    volumes: *airflow-common-volumes

  api_sei:
    profiles:
      - all
      - externo
    image: ${DOCKER_REGISTRY:-}api_sei:${API_SEI_IMAGE}
    build:
      context: .
      dockerfile: ./api_sei.dockerfile
      network: host
      args:
        NB_USER: ${NB_USER}
        NB_UID: ${NB_UID}
        NB_GID: ${NB_GID}

    command: opentelemetry-instrument gunicorn -k uvicorn.workers.UvicornH11Worker --reload --bind=0.0.0.0:8082 api_sei.main:app
    environment:
      <<: 
        - *airflow-common-env
        - *otel-common-env
      TZ: America/Sao_Paulo
      LD_PRELOAD: ''
      LOG_LEVEL: ${LOG_LEVEL}
    ports:
      - "8082:8082"
    networks:
      - network1
    restart: always
    deploy:
      resources:
        limits:
          memory: ${API_SEI_MEM_LIMIT}
          cpus: ${API_SEI_CPU_LIMIT}
    healthcheck:
      test: ["CMD", "sh", "healthcheck.sh"]
      start_period: 20s
      interval: 10s
      timeout: 10s
      retries: 5
    volumes:
      - ${STORAGE_PROJ_DIR}:${STORAGE_PROJ_DIR}

  jobs_api:
    profiles:
      - all
      - airflow
      - externo
    image: ${DOCKER_REGISTRY:-}jobs_api:${AIRFLOW_IMAGE_NAME}
    build:
      context: .
      dockerfile: ./jobs_api.dockerfile
      network: host
      args:
        NB_USER: ${NB_USER}
        NB_UID: ${NB_UID}
        NB_GID: ${NB_GID}

    command: gunicorn -k uvicorn.workers.UvicornH11Worker --reload --bind=0.0.0.0:8642 jobs.api:app
    environment:
      <<: *airflow-common-env
      TZ: America/Sao_Paulo
      AIRFLOW_DB_EXTERNAL_CONNECTION: 'false'
      LD_PRELOAD: ''
      LOG_LEVEL: ${LOG_LEVEL}
    networks:
      - network1
    restart: always
    ports:
      - "8642:8642"
    deploy:
      resources:
        limits:
          memory: ${API_SEI_MEM_LIMIT}
          cpus: ${API_SEI_CPU_LIMIT}
    volumes: *airflow-common-volumes

  app-api-feedback:
    profiles:
      - all
      - externo
    image: ${DOCKER_REGISTRY:-}app-api-feedback:${APP_API}
    build:
      context: .
      dockerfile: ./app-api-feedback.dockerfile
      network: host
      args:
        NB_USER: ${NB_USER}
        NB_UID: ${NB_UID}
        NB_GID: ${NB_GID}

    command: uvicorn main:app --reload --port 8086 --host 0.0.0.0
    environment:
      <<: *airflow-common-env
      TZ: America/Sao_Paulo
      LD_PRELOAD: ""
      LOG_LEVEL: ${LOG_LEVEL}
    ports:
      - "8086:8086"
    networks:
      - network1
    restart: always
    deploy:
      resources:
        limits:
          memory: ${APP_API_MEM_LIMIT}
          cpus: ${APP_API_CPU_LIMIT}
    healthcheck:
      test: ["CMD", "sh", "healthcheck.sh"]
      start_period: 20s
      interval: 10s
      timeout: 10s
      retries: 5
    volumes:
      - ${STORAGE_PROJ_DIR}:${STORAGE_PROJ_DIR}
  
  solr_pd:
    profiles:
      - all
      - externo
    image: ${DOCKER_REGISTRY:-}solr_pd:${SOLR_CONTAINER}
    build:
      context: .
      dockerfile: ./solr.dockerfile
      network: host
    environment:
      TZ: America/Sao_Paulo
      SOLR_JAVA_MEM: ${SOLR_JAVA_MEM}
      SOLR_MLT_PROCESS_CORE: ${SOLR_MLT_PROCESS_CORE}
      SOLR_MLT_JURISPRUDENCE_CORE: ${SOLR_MLT_JURISPRUDENCE_CORE}
      SOLR_OPTS: "-Dsolr.jetty.request.header.size=65535 -Dlog4j.configurationFile=/opt/solr/server/resources/log4j2.xml"
      LOG_LEVEL: ${LOG_LEVEL}
    volumes:
      - solr-db-volume:/var/solr
      - ./healthcheck/scripts:/healthcheck
      - /var/sei_similaridade/backup/solr/:/backup
      - ./backup/volumes/solr.sh:/opt/solr-9.0.0/backup.sh
    user: root # run as root to change the permissions of the solr folder
    # Change permissions of the solr folder, create a default core and start solr as solr user
    networks:
      - network1
    command: bash -c " chown -R 8983:8983 /var/solr && runuser -u solr -- solr-precreate default-core"
    #command: bash -c "chown -R 8983:8983 /var/solr; ( ([ -d /var/solr/data/$SOLR_MLT_PROCESS_CORE ] && echo Core $SOLR_MLT_PROCESS_CORE already exists || (wait-for-solr.sh && runuser -u solr -- solr create_core -c $SOLR_MLT_PROCESS_CORE -d /var/solr/configsets/process)) &); runuser -u solr -- solr-precreate $SOLR_MLT_JURISPRUDENCE_CORE /var/solr/configsets/jurisprudence"
    # command: bash -c "\
    #   echo 'America/Sao_Paulo' > /etc/timezone; \
    #   ln -sf /usr/share/zoneinfo/America/Sao_Paulo /etc/localtime; \
    #   dpkg-reconfigure -f noninteractive tzdata; \
    #   chmod +x /opt/solr-9.0.0/backup.sh; \
    #   echo '55 23 * * * /opt/solr-9.0.0/backup.sh' | crontab -; \
    #   touch /var/log/cron.log; \
    #   service cron start; \
    #   chown -R 8983:8983 /var/solr; \
    #   ( ([ -d /var/solr/data/$SOLR_MLT_PROCESS_CORE ] && echo Core $SOLR_MLT_PROCESS_CORE already exists || (wait-for-solr.sh && runuser -u solr -- solr create_core -c $SOLR_MLT_PROCESS_CORE -d /var/solr/configsets/process)) &); \
    #   runuser -u solr -- solr-precreate $SOLR_MLT_JURISPRUDENCE_CORE /var/solr/configsets/jurisprudence"

    restart: always
    deploy:
      resources:
        limits:
          memory: ${SOLR_MEM_LIMIT}
          cpus: ${SOLR_CPU_LIMIT}

    healthcheck:
      test: ["CMD", "sh", "/healthcheck/solr.sh"]
      start_period: 60s
      interval: 10s
      timeout: 10s
      retries: 5

  # pgvector_pd:
  #   profiles:
  #     - all
  #     # - externo
  #   image: pgvector/pgvector:0.7.0-pg15
  #   environment:
  #     TZ: America/Sao_Paulo
  #     POSTGRES_USER: ${POSTGRES_USER}
  #     POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
  #     POSTGRES_DB: sei_similaridade
  #   volumes:
  #     - pgvector-db-volume:/var/lib/postgresql/data
  #     - ./database_init/:/docker-entrypoint-initdb.d/
  #     - ./database_init/conf/postgresql.conf:/etc/postgresql/postgresql.conf
  #     - /opt/sei_similaridade:/opt/sei_similaridade/host/
  #     - /var/sei_similaridade/backup/postgresql/:/backup

  # #   command: postgres -c config_file=/etc/postgresql/postgresql.conf

  #   healthcheck:
  #     test:
  #       [
  #         "CMD",
  #         "pg_isready",
  #         "-U",
  #         "${POSTGRES_USER}",
  #         "-d",
  #         "sei_similaridade",
  #       ]
  #     interval: 30s
  #     retries: 5
  #     start_period: 5s
  #   restart: always
  #   networks:
  #     - network1
  #   deploy:
  #     resources:
  #       limits:
  #         memory: ${PGVECTOR_MEM_LIMIT}
  #         cpus: ${PGVECTOR_CPU_LIMIT}

  exporter_agent_monitor:
    profiles:
      - all
    image: node-exporter:v1.7.0
    build:
      context: .
      dockerfile: node-exporter/node-exporter.dockerfile
      network: host
    ports:
      - 50053:9100
      - 50054:9104
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    restart: unless-stopped
    networks:
      - network1
    environment:
      - DB_SEI_USER=${DB_SEI_USER}
      - DB_SEI_HOST=${DB_SEI_HOST}
      - DB_SEI_PORT=${DB_SEI_PORT}
      - SEIWS_HOST=${SEIWS_HOST}
      - SEIWS_PORT=${SEIWS_PORT}
      - SEI_SOLR_ADDRESS=${SEI_SOLR_ADDRESS}
      - ENVIRONMENT=${ENVIRONMENT}
      - MYSQLD_EXPORTER_PASSWORD=${DB_SEI_PWD}
      - SOLR_ADDRESS=${SOLR_ADDRESS}
      - SOLR_MLT_PROCESS_CORE=${SOLR_MLT_PROCESS_CORE}
      - SOLR_MLT_JURISPRUDENCE_CORE=${SOLR_MLT_JURISPRUDENCE_CORE} 
    deploy:
      resources:
        limits:
          memory: 50mb
          cpus: "1"

  cadvisor_agent_monitor:
    profiles:
      - all
    image: gcr.io/cadvisor/cadvisor:v0.49.1
    privileged: true
    ports:
      - 50055:8080
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /cgroup:/cgroup:ro
    restart: unless-stopped
    networks:
      - network1
    deploy:
      resources:
        limits:
          memory: 300mb
          cpus: "1"

  api_assistente:
    image: ${DOCKER_REGISTRY:-}api_assistente:${API_ASSISTENTE_VERSION}
    profiles:
      - all
      - externo
    build:
      dockerfile: assistente.dockerfile
      network: host
      args:
        GIT_TOKEN: ${GIT_TOKEN}
        EMBEDDER_PROJ_URL: ${EMBEDDER_PROJ_URL}
    restart: always
    env_file:
      - env_files/default.env
      - env_files/${ENVIRONMENT}.env
      - env_files/security.env
    environment:
      <<: *airflow-common-env
      POSTGRES_DB_ASSISTENTE_SCHEMA: ${POSTGRES_DB_ASSISTENTE_SCHEMA}
      ASSISTENTE_LANGFUSE_URL: ${ASSISTENTE_LANGFUSE_URL}
      ASSISTENTE_LANGFUSE_PUBLIC_KEY: ${ASSISTENTE_LANGFUSE_PUBLIC_KEY}
      ASSISTENTE_LANGFUSE_SECRET_KEY: ${ASSISTENTE_LANGFUSE_SECRET_KEY}
      ASSISTENTE_LANGFUSE_SECRET_NEXTAUTH_SECRET: ${ASSISTENTE_LANGFUSE_SECRET_NEXTAUTH_SECRET}
      ASSISTENTE_LANGFUSE_SECRET_SALT: ${ASSISTENTE_LANGFUSE_SECRET_SALT}
      TIMEOUT_API: 600
      LOG_LEVEL: ${LOG_LEVEL}
      LOGLEVEL : ${LOGLEVEL}
      USE_LANGFUSE: ${USE_LANGFUSE}
      TZ: "America/Sao_Paulo"
      OPENAI_API_VERSION: ${OPENAI_API_VERSION}
      AZURE_OPENAI_ENDPOINT: ${AZURE_OPENAI_ENDPOINT}
      MAX_RETRIE: ${MAX_RETRIES}
      AZURE_OPENAI_ENDPOINT_GPT4o: ${AZURE_OPENAI_ENDPOINT_GPT4o}
      AZURE_OPENAI_KEY_GPT4o: ${AZURE_OPENAI_KEY_GPT4o}
      GPT_MODEL_4o_128k: ${GPT_MODEL_4o_128k}
      AZURE_OPENAI_ENDPOINT_GPT4o_mini: ${AZURE_OPENAI_ENDPOINT_GPT4o_mini}
      AZURE_OPENAI_KEY_GPT4o_mini: ${AZURE_OPENAI_KEY_GPT4o_mini}
      GPT_MODEL_4o_mini_128k: ${GPT_MODEL_4o_mini_128k}
      TOKEN_MAX: 4096
      SEI_IAWS_URL : ${SEI_IAWS_URL}
      SEI_IAWS_KEY : ${SEI_IAWS_KEY}
      LD_LIBRARY_PATH: /opt/oracle
      ORACLE_HOME: /opt/oracle
      ORACLE_VERSION: 19.25

    # ports:
    #   - "8088:8088"
    command: "gunicorn main:app -c /app/core/gunicorn_conf.py"
    networks:
      - network1
    deploy:
      resources:
        limits:
          memory: ${ASSISTENTE_MEM_LIMIT}
          cpus: ${ASSISTENTE_CPU_LIMIT}
    volumes:
      - ${STORAGE_PROJ_DIR}:${STORAGE_PROJ_DIR}


  pgvector_all:
    profiles:
      - all
      - externo
    image: ${DOCKER_REGISTRY:-}pgvector_all:${POSTGRES_IMAGE}
    build:
      dockerfile: pgvector_all.dockerfile
#      # Variáveis não são mais usadas em tempo de build - Taiga 896
#      args:
#        POSTGRES_USER: ${ASSISTENTE_PGVECTOR_USER}
#        POSTGRES_DB: ${ASSISTENTE_PGVECTOR_DB}
#        POSTGRES_DB_SIMILARIDADE: ${POSTGRES_DATABASE}

      network: host
    restart: always
    environment:
      POSTGRES_DB: ${ASSISTENTE_PGVECTOR_DB}
      POSTGRES_DB_SIMILARIDADE: ${POSTGRES_DATABASE}
      POSTGRES_DB_ASSISTENTE_SCHEMA: ${POSTGRES_DB_ASSISTENTE_SCHEMA}
      POSTGRES_USER: ${ASSISTENTE_PGVECTOR_USER}
      POSTGRES_PASSWORD: ${ASSISTENTE_PGVECTOR_PWD}
      POSTGRES_MAX_CONNECTIONS: 100
      POSTGRES_IDLE_IN_TRANSACTION_SESSION_TIMEOUT: 360000
      TZ: "America/Sao_Paulo"
    entrypoint: >
      /bin/bash -c "
      echo 'export POSTGRES_USER=${ASSISTENTE_PGVECTOR_USER}' > /etc/custom_env_vars_assistente.sh &&
      echo 'export POSTGRES_PASSWORD=${ASSISTENTE_PGVECTOR_PWD}' >> /etc/custom_env_vars_assistente.sh &&
      echo 'export POSTGRES_DB=${ASSISTENTE_PGVECTOR_DB}' >> /etc/custom_env_vars_assistente.sh &&
      echo 'export PGDATA=/var/lib/postgresql/data' >> /etc/custom_env_vars_assistente.sh &&
      echo 'export TZ=America/Sao_Paulo' >> /etc/custom_env_vars_assistente.sh &&
      chmod +x /etc/custom_env_vars_assistente.sh &&
      echo 'export POSTGRES_USER=${ASSISTENTE_PGVECTOR_USER}' > /etc/custom_env_vars_similaridade.sh &&
      echo 'export POSTGRES_PASSWORD=${ASSISTENTE_PGVECTOR_PWD}' >> /etc/custom_env_vars_similaridade.sh &&
      echo 'export POSTGRES_DB=${POSTGRES_DATABASE}' >> /etc/custom_env_vars_similaridade.sh &&
      echo 'export PGDATA=/var/lib/postgresql/data' >> /etc/custom_env_vars_similaridade.sh &&
      echo 'export TZ=America/Sao_Paulo' >> /etc/custom_env_vars_similaridade.sh &&
      chmod +x /etc/custom_env_vars_similaridade.sh &&
      sei_ia-entrypoint.sh"
    volumes:
      - pgvector-db-volume-all:/var/lib/postgresql/data
      - /var/sei_similaridade/backup/postgresql/:/backup
    networks:
      - network1
    deploy:
      resources:
        limits:
          memory: ${PGVECTOR_MEM_LIMIT}
          cpus: ${PGVECTOR_CPU_LIMIT}


  nginx_assistente:
    profiles:
      - all
      - externo
    image: ${DOCKER_REGISTRY:-}nginx_assistente:${NGINX_ASSISTENTE_VERSION}
    build:
      dockerfile: nginx.dockerfile
      network: host
    ports:
      - "8088:80"
    depends_on:
      - api_assistente
    networks:
      - network1
    deploy:
      resources:
        limits:
          memory: ${ASSISTENTE_NGINX_MEM_LIMIT}
          cpus: ${ASSISTENTE_NGINX_CPU_LIMIT}

  langfuse_assistente:
    profiles:
      - all
    image: langfuse/langfuse:2.57.0
    ports:
      - "3005:3005"
    environment:
      - DATABASE_URL=postgresql://${ASSISTENTE_PGVECTOR_USER}:${ASSISTENTE_PGVECTOR_PWD}@${ASSISTENTE_PGVECTOR_HOST}:${ASSISTENTE_PGVECTOR_PORT}/langfuse
      - NEXTAUTH_SECRET=${ASSISTENTE_LANGFUSE_SECRET_NEXTAUTH_SECRET}
      - SALT=${ASSISTENTE_LANGFUSE_SECRET_SALT}
      - NEXTAUTH_URL=${ASSISTENTE_LANGFUSE_URL}
      - PORT=3005
    depends_on:
      pgvector_all:
        condition: service_healthy
    networks:
      - network1
    restart: always
    deploy:
      resources:
        limits:
          memory: ${ASSISTENTE_LANGFUSE_MEM_LIMIT}
          cpus: ${ASSISTENTE_LANGFUSE_CPU_LIMIT}

volumes:
  airflow-jobs:
  airflow-postgres-db-volume:
  solr-db-volume:
  airflow-logs-volume:
  pgvector-db-volume:
  pgvector-db-volume-assistente:
  pgvector-db-volume-all:

networks:
  network1:
    name: docker-host-bridge
    external: true
